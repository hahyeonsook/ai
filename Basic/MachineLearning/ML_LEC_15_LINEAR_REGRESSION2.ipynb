{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data.ndim =  2 , x_data.shape =  (25, 3)\n",
      "t_data.ndim =  2 , t_data.shape =  (25, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "loaded_data = np.loadtxt('./data-01-test-score.csv', delimiter=\",\", dtype=np.float32)\n",
    "\n",
    "x_data = loaded_data[ :, 0:-1]\n",
    "t_data = loaded_data[ :, [-1]]\n",
    "\n",
    "# 데이터 차원 및 shape 확인\n",
    "print(\"x_data.ndim = \", x_data.ndim, \", x_data.shape = \", x_data.shape)\n",
    "print(\"t_data.ndim = \", t_data.ndim, \", t_data.shape = \", t_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W =  [[0.33367899]\n",
      " [0.529313  ]\n",
      " [0.72064417]] , W.shape =  (3, 1) , b =  [0.92608071] , b.shape =  (1,)\n"
     ]
    }
   ],
   "source": [
    "W = np.random.rand(3, 1) # 3X1 행렬\n",
    "b = np.random.rand(1)\n",
    "print(\"W = \", W, \", W.shape = \", W.shape, \", b = \", b, \", b.shape = \", b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(x, t):\n",
    "    y = np.dot(x, W) + b\n",
    "    \n",
    "    return (np.sum((t - y)**2)) / (len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_derivative(f, x):\n",
    "    delta_x = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x) #f(x + delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val - delta_x\n",
    "        fx2 = f(x) # f(x - delta_x)\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val\n",
    "        it.iternext()\n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실 함수 값 계산 함수\n",
    "# 입력변수 x, t : numpy type\n",
    "def error_val(x, t):\n",
    "    y = np.dot(x, W) + b\n",
    "    \n",
    "    return ((np.sum((t - y)**2)) / (len(x)))\n",
    "\n",
    "# 학습을 마친 후, 임의의 데이터에 대해 미래 값 예측 함수\n",
    "# 입력변수 x : numpy type\n",
    "def predict(x):\n",
    "    y = np.dot(x, W) + b\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial error value =  1189.0575203721921 Initial W =  [[0.33367899]\n",
      " [0.529313  ]\n",
      " [0.72064417]] \n",
      " , b =  [0.92608071]\n",
      "step =  0 error value =  444.8676470905445 W =  [[0.38855639]\n",
      " [0.58445008]\n",
      " [0.77724662]] , b =  [0.92649312]\n",
      "step =  400 error value =  7.715865059438881 W =  [[0.46173462]\n",
      " [0.64310848]\n",
      " [0.90295851]] , b =  [0.92660125]\n",
      "step =  800 error value =  7.303716395987638 W =  [[0.45100013]\n",
      " [0.62087225]\n",
      " [0.93512729]] , b =  [0.92602625]\n",
      "step =  1200 error value =  7.011234474876532 W =  [[0.44139693]\n",
      " [0.60258673]\n",
      " [0.96233634]] , b =  [0.92541631]\n",
      "step =  1600 error value =  6.803261973701058 W =  [[0.43279946]\n",
      " [0.58757709]\n",
      " [0.98536711]] , b =  [0.92477678]\n",
      "step =  2000 error value =  6.655044953435888 W =  [[0.42509702]\n",
      " [0.57528142]\n",
      " [1.00487624]] , b =  [0.92411222]\n",
      "step =  2400 error value =  6.549140668654243 W =  [[0.41819189]\n",
      " [0.56523203]\n",
      " [1.02141566]] , b =  [0.92342645]\n",
      "step =  2800 error value =  6.473246983397774 W =  [[0.41199769]\n",
      " [0.55703986]\n",
      " [1.03544948]] , b =  [0.92272268]\n",
      "step =  3200 error value =  6.418678255402017 W =  [[0.40643798]\n",
      " [0.55038144]\n",
      " [1.04736806]] , b =  [0.92200366]\n",
      "step =  3600 error value =  6.379294774760416 W =  [[0.40144502]\n",
      " [0.54498798]\n",
      " [1.05749987]] , b =  [0.92127168]\n",
      "step =  4000 error value =  6.350750479267405 W =  [[0.39695873]\n",
      " [0.54063628]\n",
      " [1.06612137]] , b =  [0.92052869]\n",
      "step =  4400 error value =  6.32996407269077 W =  [[0.39292574]\n",
      " [0.53714114]\n",
      " [1.07346541]] , b =  [0.91977633]\n",
      "step =  4800 error value =  6.31474699842427 W =  [[0.38929861]\n",
      " [0.534349  ]\n",
      " [1.07972813]] , b =  [0.919016]\n",
      "step =  5200 error value =  6.303541581583163 W =  [[0.3860351 ]\n",
      " [0.53213265]\n",
      " [1.08507487]] , b =  [0.91824889]\n",
      "step =  5600 error value =  6.295236579169325 W =  [[0.3830976 ]\n",
      " [0.53038683]\n",
      " [1.08964505]] , b =  [0.91747599]\n",
      "step =  6000 error value =  6.289037144687911 W =  [[0.38045255]\n",
      " [0.52902449]\n",
      " [1.09355632]] , b =  [0.91669816]\n",
      "step =  6400 error value =  6.2843730640712625 W =  [[0.37807002]\n",
      " [0.52797377]\n",
      " [1.09690799]] , b =  [0.91591612]\n",
      "step =  6800 error value =  6.280833925566821 W =  [[0.37592325]\n",
      " [0.52717541]\n",
      " [1.09978398]] , b =  [0.91513048]\n",
      "step =  7200 error value =  6.278123258328021 W =  [[0.37398832]\n",
      " [0.5265806 ]\n",
      " [1.10225521]] , b =  [0.91434177]\n",
      "step =  7600 error value =  6.276026041083322 W =  [[0.37224385]\n",
      " [0.52614922]\n",
      " [1.10438166]] , b =  [0.91355044]\n",
      "step =  8000 error value =  6.274385643696441 W =  [[0.37067067]\n",
      " [0.52584836]\n",
      " [1.10621413]] , b =  [0.91275686]\n",
      "step =  8400 error value =  6.273087431168849 W =  [[0.36925161]\n",
      " [0.52565106]\n",
      " [1.10779564]] , b =  [0.91196135]\n",
      "step =  8800 error value =  6.272047079276499 W =  [[0.36797129]\n",
      " [0.52553528]\n",
      " [1.10916267]] , b =  [0.9111642]\n",
      "step =  9200 error value =  6.271202227080332 W =  [[0.3668159 ]\n",
      " [0.52548309]\n",
      " [1.11034617]] , b =  [0.91036565]\n",
      "step =  9600 error value =  6.2705064966047 W =  [[0.36577303]\n",
      " [0.52547991]\n",
      " [1.11137243]] , b =  [0.90956589]\n",
      "step =  10000 error value =  6.269925194956369 W =  [[0.36483156]\n",
      " [0.52551393]\n",
      " [1.1122638 ]] , b =  [0.90876511]\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-5  # 1e-2, 1e-3은 손실함수 값 발산\n",
    "\n",
    "f = lambda x : loss_func(x_data, t_data)\n",
    "\n",
    "print(\"Initial error value = \", error_val(x_data, t_data), \"Initial W = \", W, \"\\n\", \", b = \", b)\n",
    "\n",
    "for step in range(10001):\n",
    "\n",
    "    W -= learning_rate * numerical_derivative(f, W)\n",
    "    \n",
    "    b -= learning_rate * numerical_derivative(f, b)\n",
    "    \n",
    "    if(step % 400 == 0):\n",
    "        print(\"step = \", step, \"error value = \", error_val(x_data, t_data), \"W = \", W, \", b = \", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([178.98565445])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = np.array([100, 98, 81])\n",
    "\n",
    "predict(test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
